{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "\n",
    "    <td><img src=https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTZcU0_2fgIIcOXf6T0U0AQq1Ld4wMw9s1at5scGVpT5VEmPPTq6-CRSGJhQkrSSrSfi7o&usqp=CAU alt=\"Drawing\" style=\"width: 70px;\"/></td>\n",
    "\n",
    "    <td><td style=\"font-size:3vw\"><font color='OrangeRed'><b>Trabajo Final Master en Big Data</b></font></td>\n",
    "\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "\n",
    "    <td><img src=https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTZcU0_2fgIIcOXf6T0U0AQq1Ld4wMw9s1at5scGVpT5VEmPPTq6-CRSGJhQkrSSrSfi7o&usqp=CAU alt=\"Drawing\" style=\"width: 70px;\"/></td>\n",
    "\n",
    "    <td><td style=\"font-size:3vw\"><font color='OrangeRed'><b>Trabajo Final Master en Big Data</b></font></td>\n",
    "\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Final - Máster en Big Data - Fernández, García y Payovich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Base: Random Forest, Bagging, Boosting y Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split # División del dataset\n",
    "import matplotlib.pyplot as plt # Plotear\n",
    "from sklearn.linear_model import LinearRegression # Modelo de ML\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, classification_report # Métricas\n",
    "pd.options.display.max_columns= None\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación y Transformación de las Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base_final_EDA.csv', delimiter= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['detractor'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r = dfr.drop(['detractor'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['detractor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_r = dfr['detractor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampleo y Escalado de Datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OverSampling:\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 42)\n",
    "x_sm, y_sm = sm.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "x_us, y_us = rus.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rf, x_test_rf, y_train_rf, y_test_rf = train_test_split(x, y,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_rf = sc.fit_transform(x_train_rf)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_rf = sc.fit_transform(x_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state = 50, n_estimators = 500)\n",
    "rf.fit(x_train_rf, y_train_rf)\n",
    "y_pred_rf = rf.predict(x_test_rf).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo Random Forest: 0.829\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf = accuracy_score(y_test_rf, y_pred_rf)\n",
    "print('Accuracy del modelo Random Forest: %.3f' % accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo Random Forest: 0.000\n"
     ]
    }
   ],
   "source": [
    "precision_rf = precision_score(y_test_rf, y_pred_rf)\n",
    "print('Precision del modelo Random Forest: %.3f' % precision_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo Random Forest: 0.000\n"
     ]
    }
   ],
   "source": [
    "recall_rf = recall_score(y_test_rf, y_pred_rf)\n",
    "print('Recall del Modelo Random Forest: %.3f' % recall_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[1935    0]\n",
      " [ 398    0]]\n"
     ]
    }
   ],
   "source": [
    "matriz_rf = confusion_matrix(y_test_rf, y_pred_rf)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      1.00      0.91      1935\n",
      "        True       0.00      0.00      0.00       398\n",
      "\n",
      "    accuracy                           0.83      2333\n",
      "   macro avg       0.41      0.50      0.45      2333\n",
      "weighted avg       0.69      0.83      0.75      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rf, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest con Oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sm, x_test_sm, y_train_sm, y_test_sm = train_test_split(x_sm, y_sm,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_sm = sc.fit_transform(x_train_sm)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_sm = sc.fit_transform(x_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_sm = RandomForestClassifier(random_state = 50, n_estimators = 500)\n",
    "rf_sm.fit(x_train_sm, y_train_sm)\n",
    "y_pred_sm = rf_sm.predict(x_test_sm).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Random Forest con Oversampling: 0.696\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf_sm = accuracy_score(y_test_sm, y_pred_sm)\n",
    "print('Accuracy del Random Forest con Oversampling: %.3f' % accuracy_rf_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo Random Forest con Oversampling: 0.634\n"
     ]
    }
   ],
   "source": [
    "precision_sm = precision_score(y_test_sm, y_pred_sm)\n",
    "print('Precision del modelo Random Forest con Oversampling: %.3f' % precision_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo Random Forest con Oversampling: 0.935\n"
     ]
    }
   ],
   "source": [
    "recall_sm = recall_score(y_test_sm, y_pred_sm)\n",
    "print('Recall del Modelo Random Forest con Oversampling: %.3f' % recall_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[ 885 1067]\n",
      " [ 128 1845]]\n"
     ]
    }
   ],
   "source": [
    "matriz_sm = confusion_matrix(y_test_sm, y_pred_sm)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.45      0.60      1952\n",
      "        True       0.63      0.94      0.76      1973\n",
      "\n",
      "    accuracy                           0.70      3925\n",
      "   macro avg       0.75      0.69      0.68      3925\n",
      "weighted avg       0.75      0.70      0.68      3925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sm, y_pred_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest con Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_us, x_test_us, y_train_us, y_test_us = train_test_split(x_us, y_us,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_us = sc.fit_transform(x_train_us)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_us = sc.fit_transform(x_test_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_us = RandomForestClassifier(random_state = 50, n_estimators = 500)\n",
    "rf_us.fit(x_train_us, y_train_us)\n",
    "y_pred_us = rf_us.predict(x_test_us).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Random Forest con Undersampling: 0.589\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf_us = accuracy_score(y_test_us, y_pred_us)\n",
    "print('Accuracy del Random Forest con Undersampling: %.3f' % accuracy_rf_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo Random Forest con Undersampling 0.576\n"
     ]
    }
   ],
   "source": [
    "precision_us = precision_score(y_test_us, y_pred_us)\n",
    "print('Precision del modelo Random Forest con Undersampling %.3f' % precision_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo Random Forest con Undersampling: 0.560\n"
     ]
    }
   ],
   "source": [
    "recall_us = recall_score(y_test_us, y_pred_us)\n",
    "print('Recall del Modelo Random Forest con Undersampling: %.3f' % recall_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[236 147]\n",
      " [157 200]]\n"
     ]
    }
   ],
   "source": [
    "matriz_us = confusion_matrix(y_test_us, y_pred_us)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.62      0.61       383\n",
      "        True       0.58      0.56      0.57       357\n",
      "\n",
      "    accuracy                           0.59       740\n",
      "   macro avg       0.59      0.59      0.59       740\n",
      "weighted avg       0.59      0.59      0.59       740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_us, y_pred_us))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bg, x_test_bg, y_train_bg, y_test_bg = train_test_split(x, y,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_bg = sc.fit_transform(x_train_bg)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_bg = sc.fit_transform(x_test_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sm_bg, x_test_sm_bg, y_train_sm_bg, y_test_sm_bg = train_test_split(x_sm, y_sm,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_sm_bg = sc.fit_transform(x_train_sm_bg)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_sm_bg = sc.fit_transform(x_test_sm_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(n_jobs=-1, random_state=55)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging = BaggingClassifier(n_estimators = 10,\n",
    "                            random_state = 55, n_jobs = -1)\n",
    "\n",
    "bagging.fit(x_train_bg, y_train_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(n_jobs=-1, random_state=55)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging = BaggingClassifier(n_estimators = 10,\n",
    "                            random_state = 55, n_jobs = -1)\n",
    "\n",
    "bagging.fit(x_train_sm_bg, y_train_sm_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bg = bagging.predict(x_test_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sm_bg = bagging.predict(x_test_sm_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Bagging: 0.439\n"
     ]
    }
   ],
   "source": [
    "accuracy_bg = accuracy_score(y_test_bg, y_pred_bg)\n",
    "print('Accuracy del Modelo de Bagging: %.3f' % accuracy_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Bagging con Oversampling: 0.738\n"
     ]
    }
   ],
   "source": [
    "accuracy_sm_bg = accuracy_score(y_test_sm_bg, y_pred_sm_bg)\n",
    "print('Accuracy del Modelo de Bagging con Oversampling: %.3f' % accuracy_sm_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Bagging: 0.208\n"
     ]
    }
   ],
   "source": [
    "precision_bg = precision_score(y_test_bg, y_pred_bg)\n",
    "print('Precision del Modelo de Bagging: %.3f' % precision_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Bagging con Oversampling: 0.683\n"
     ]
    }
   ],
   "source": [
    "precision_sm_bg = precision_score(y_test_sm_bg, y_pred_sm_bg)\n",
    "print('Precision del Modelo de Bagging con Oversampling: %.3f' % precision_sm_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Bagging: 0.814\n"
     ]
    }
   ],
   "source": [
    "recall_bg = recall_score(y_test_bg, y_pred_bg)\n",
    "print('Recall del Modelo de Bagging: %.3f' % recall_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Bagging con Oversampling: 0.881\n"
     ]
    }
   ],
   "source": [
    "recall_sm_bg = recall_score(y_test_sm_bg, y_pred_sm_bg)\n",
    "print('Recall del Modelo de Bagging con Oversampling: %.3f' % recall_sm_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión Bagging:\n",
      "[[ 701 1234]\n",
      " [  74  324]]\n"
     ]
    }
   ],
   "source": [
    "matriz_bg = confusion_matrix(y_test_bg, y_pred_bg)\n",
    "print('Matriz de Confusión Bagging:')\n",
    "print(matriz_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión Bagging con Oversampling:\n",
      "[[1172  798]\n",
      " [ 232 1723]]\n"
     ]
    }
   ],
   "source": [
    "matriz_sm_bg = confusion_matrix(y_test_sm_bg, y_pred_sm_bg)\n",
    "print('Matriz de Confusión Bagging con Oversampling:')\n",
    "print(matriz_sm_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.36      0.52      1935\n",
      "        True       0.21      0.81      0.33       398\n",
      "\n",
      "    accuracy                           0.44      2333\n",
      "   macro avg       0.56      0.59      0.42      2333\n",
      "weighted avg       0.79      0.44      0.49      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bg, y_pred_bg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.59      0.69      1970\n",
      "        True       0.68      0.88      0.77      1955\n",
      "\n",
      "    accuracy                           0.74      3925\n",
      "   macro avg       0.76      0.74      0.73      3925\n",
      "weighted avg       0.76      0.74      0.73      3925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sm_bg, y_pred_sm_bg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_boo, x_test_boo, y_train_boo, y_test_boo = train_test_split(x, y,\n",
    "                                   random_state=42, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_boo = sc.fit_transform(x_train_boo)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_boo = sc.fit_transform(x_test_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sm_boo, x_test_sm_boo, y_train_sm_boo, y_test_sm_boo = train_test_split(x_sm, y_sm,\n",
    "                                   random_state=42, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_sm_boo = sc.fit_transform(x_train_sm_boo)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_sm_boo = sc.fit_transform(x_test_sm_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='logloss', gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=3, max_leaves=0,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "boosting = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "boosting.fit(x_train_boo, y_train_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='logloss', gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=3, max_leaves=0,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting_sm = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "boosting_sm.fit(x_train_sm_boo, y_train_sm_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Boosting: 0.841\n"
     ]
    }
   ],
   "source": [
    "y_pred_boo = boosting.predict(x_test_boo)\n",
    "accuracy_boo = accuracy_score(y_test_boo, y_pred_boo)\n",
    "print('Accuracy del Modelo de Boosting: %.3f' % accuracy_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Boosting con Oversampling: 0.588\n"
     ]
    }
   ],
   "source": [
    "y_pred_sm_boo = boosting_sm.predict(x_test_sm_boo)\n",
    "accuracy_sm_boo = accuracy_score(y_test_sm_boo, y_pred_sm_boo)\n",
    "print('Accuracy del Modelo de Boosting con Oversampling: %.3f' % accuracy_sm_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Boosting: 0.000\n"
     ]
    }
   ],
   "source": [
    "precision_boo = precision_score(y_test_boo, y_pred_boo)\n",
    "print('Precision del Modelo de Boosting: %.3f' % precision_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Boosting con Oversampling: 0.553\n"
     ]
    }
   ],
   "source": [
    "precision_sm_boo = precision_score(y_test_sm_boo, y_pred_sm_boo)\n",
    "print('Precision del Modelo de Boosting con Oversampling: %.3f' % precision_sm_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Boosting: 0.000\n"
     ]
    }
   ],
   "source": [
    "recall_boo = recall_score(y_test_boo, y_pred_boo)\n",
    "print('Recall del Modelo de Boosting: %.3f' % recall_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Boosting con Oversampling: 0.921\n"
     ]
    }
   ],
   "source": [
    "recall_sm_boo = recall_score(y_test_sm_boo, y_pred_sm_boo)\n",
    "print('Recall del Modelo de Boosting con Oversampling: %.3f' % recall_sm_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de Boosting:\n",
      "[[1962    0]\n",
      " [ 371    0]]\n"
     ]
    }
   ],
   "source": [
    "matriz_boo = confusion_matrix(y_test_boo, y_pred_boo)\n",
    "print('Matriz de Confusión de Boosting:')\n",
    "print(matriz_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de Boosting con Oversampling:\n",
      "[[ 502 1462]\n",
      " [ 155 1806]]\n"
     ]
    }
   ],
   "source": [
    "matriz_sm_boo = confusion_matrix(y_test_sm_boo, y_pred_sm_boo)\n",
    "print('Matriz de Confusión de Boosting con Oversampling:')\n",
    "print(matriz_sm_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      1.00      0.91      1962\n",
      "        True       0.00      0.00      0.00       371\n",
      "\n",
      "    accuracy                           0.84      2333\n",
      "   macro avg       0.42      0.50      0.46      2333\n",
      "weighted avg       0.71      0.84      0.77      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_boo, y_pred_boo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.26      0.38      1964\n",
      "        True       0.55      0.92      0.69      1961\n",
      "\n",
      "    accuracy                           0.59      3925\n",
      "   macro avg       0.66      0.59      0.54      3925\n",
      "weighted avg       0.66      0.59      0.54      3925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sm_boo, y_pred_sm_boo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_st, x_test_st, y_train_st, y_test_st = train_test_split(x, y,\n",
    "                                   random_state=42, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_st = sc.fit_transform(x_train_st)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_st = sc.fit_transform(x_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sm_st, x_test_sm_st, y_train_sm_st, y_test_sm_st = train_test_split(x_sm, y_sm,\n",
    "                                   random_state=42, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_sm_st = sc.fit_transform(x_train_sm_st)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_sm_st = sc.fit_transform(x_test_sm_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
       "                               ('gb',\n",
       "                                BaggingClassifier(n_estimators=100,\n",
       "                                                  random_state=42))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos_stacking = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', BaggingClassifier(n_estimators=100, random_state=42)),\n",
    "]\n",
    "\n",
    "meta_modelo = LogisticRegression()\n",
    "\n",
    "stacking = StackingClassifier(estimators=modelos_stacking, final_estimator=meta_modelo)\n",
    "\n",
    "stacking.fit(x_train_st, y_train_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
       "                               ('gb',\n",
       "                                BaggingClassifier(n_estimators=100,\n",
       "                                                  random_state=42))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos_stacking_sm = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', BaggingClassifier(n_estimators=100, random_state=42)),\n",
    "]\n",
    "\n",
    "meta_modelo = LogisticRegression()\n",
    "\n",
    "stacking_sm = StackingClassifier(estimators=modelos_stacking, final_estimator=meta_modelo)\n",
    "\n",
    "stacking_sm.fit(x_train_sm_st, y_train_sm_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Stacking: 0.840977\n"
     ]
    }
   ],
   "source": [
    "y_pred_st = stacking.predict(x_test_st)\n",
    "accuracy_st = accuracy_score(y_test_st, y_pred_st)\n",
    "print(f'Accuracy del Modelo de Stacking: {accuracy_st:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Stacking con Oversampling: 0.502675\n"
     ]
    }
   ],
   "source": [
    "y_pred_sm_st = stacking.predict(x_test_sm_st)\n",
    "accuracy_sm_st = accuracy_score(y_test_sm_st, y_pred_sm_st)\n",
    "print(f'Accuracy del Modelo de Stacking con Oversampling: {accuracy_sm_st:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Stacking: 0.000\n"
     ]
    }
   ],
   "source": [
    "precision_st = precision_score(y_test_st, y_pred_st)\n",
    "print('Precision del Modelo de Stacking: %.3f' % precision_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Stacking con Oversampling: 0.909\n"
     ]
    }
   ],
   "source": [
    "precision_sm_st = precision_score(y_test_sm_st, y_pred_sm_st)\n",
    "print('Precision del Modelo de Stacking con Oversampling: %.3f' % precision_sm_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Stacking: 0.000\n"
     ]
    }
   ],
   "source": [
    "recall_st = recall_score(y_test_st, y_pred_st)\n",
    "print('Recall del Modelo de Stacking: %.3f' % recall_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Stacking con Oversampling: 0.005\n"
     ]
    }
   ],
   "source": [
    "recall_sm_st = recall_score(y_test_sm_st, y_pred_sm_st)\n",
    "print('Recall del Modelo de Stacking con Oversampling: %.3f' % recall_sm_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de Boosting:\n",
      "[[1962    0]\n",
      " [ 371    0]]\n"
     ]
    }
   ],
   "source": [
    "matriz_st = confusion_matrix(y_test_st, y_pred_st)\n",
    "print('Matriz de Confusión de Boosting:')\n",
    "print(matriz_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de Boosting con Oversampling:\n",
      "[[1963    1]\n",
      " [1951   10]]\n"
     ]
    }
   ],
   "source": [
    "matriz_sm_st = confusion_matrix(y_test_sm_st, y_pred_sm_st)\n",
    "print('Matriz de Confusión de Boosting con Oversampling:')\n",
    "print(matriz_sm_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      1.00      0.91      1962\n",
      "        True       0.00      0.00      0.00       371\n",
      "\n",
      "    accuracy                           0.84      2333\n",
      "   macro avg       0.42      0.50      0.46      2333\n",
      "weighted avg       0.71      0.84      0.77      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_st, y_pred_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      1.00      0.67      1964\n",
      "        True       0.91      0.01      0.01      1961\n",
      "\n",
      "    accuracy                           0.50      3925\n",
      "   macro avg       0.71      0.50      0.34      3925\n",
      "weighted avg       0.71      0.50      0.34      3925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sm_st, y_pred_sm_st))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
