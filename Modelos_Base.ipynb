{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "\n",
    "    <td><img src=https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTZcU0_2fgIIcOXf6T0U0AQq1Ld4wMw9s1at5scGVpT5VEmPPTq6-CRSGJhQkrSSrSfi7o&usqp=CAU alt=\"Drawing\" style=\"width: 70px;\"/></td>\n",
    "\n",
    "    <td><td style=\"font-size:3vw\"><font color='OrangeRed'><b>Trabajo Final Master en Big Data</b></font></td>\n",
    "\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "\n",
    "    <td><img src=https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTZcU0_2fgIIcOXf6T0U0AQq1Ld4wMw9s1at5scGVpT5VEmPPTq6-CRSGJhQkrSSrSfi7o&usqp=CAU alt=\"Drawing\" style=\"width: 70px;\"/></td>\n",
    "\n",
    "    <td><td style=\"font-size:3vw\"><font color='OrangeRed'><b>Trabajo Final Master en Big Data</b></font></td>\n",
    "\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Final - Máster en Big Data - Fernández, García y Payovich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Base: Random Forest, Bagging, Boosting y Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split # División del dataset\n",
    "import matplotlib.pyplot as plt # Plotear\n",
    "from sklearn.linear_model import LinearRegression # Modelo de ML\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, classification_report # Métricas\n",
    "pd.options.display.max_columns= None\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación y Transformación de las Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base_final_EDA.csv', delimiter= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['detractor'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r = dfr.drop(['detractor'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['detractor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_r = dfr['detractor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampleo y Escalado de Datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OverSampling:\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 42)\n",
    "x_sm, y_sm = sm.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "x_us, y_us = rus.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rf, x_test, y_train, y_test = train_test_split(x, y,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_r, x_test_r, y_train_r, y_test_r = train_test_split(x_r, y_r,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rf, x_test_rf, y_train_rf, y_test_rf = train_test_split(x, y,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_rf = sc.fit_transform(x_train_rf)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_rf = sc.fit_transform(x_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state = 50, n_estimators = 500)\n",
    "rf.fit(x_train_rf, y_train_rf)\n",
    "y_pred_rf = rf.predict(x_test_rf).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo Random Forest: 0.829\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf = accuracy_score(y_test_rf, y_pred_rf)\n",
    "print('Accuracy del modelo Random Forest: %.3f' % accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo Random Forest: 0.000\n"
     ]
    }
   ],
   "source": [
    "precision_rf = precision_score(y_test_rf, y_pred_rf)\n",
    "print('Precision del modelo Random Forest: %.3f' % precision_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo Random Forest: 0.000\n"
     ]
    }
   ],
   "source": [
    "recall_rf = recall_score(y_test_rf, y_pred_rf)\n",
    "print('Recall del Modelo Random Forest: %.3f' % recall_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[1935    0]\n",
      " [ 398    0]]\n"
     ]
    }
   ],
   "source": [
    "matriz_rf = confusion_matrix(y_test_rf, y_pred_rf)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      1.00      0.91      1935\n",
      "        True       0.00      0.00      0.00       398\n",
      "\n",
      "    accuracy                           0.83      2333\n",
      "   macro avg       0.41      0.50      0.45      2333\n",
      "weighted avg       0.69      0.83      0.75      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rf, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest con Oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sm, x_test_sm, y_train_sm, y_test_sm = train_test_split(x_sm, y_sm,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_sm = sc.fit_transform(x_train_sm)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_sm = sc.fit_transform(x_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_sm = RandomForestClassifier(random_state = 50, n_estimators = 500)\n",
    "rf_sm.fit(x_train_sm, y_train_sm)\n",
    "y_pred_sm = rf_sm.predict(x_test_sm).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Random Forest con Oversampling: 0.696\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf_sm = accuracy_score(y_test_sm, y_pred_sm)\n",
    "print('Accuracy del Random Forest con Oversampling: %.3f' % accuracy_rf_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo Random Forest con Oversampling: 0.634\n"
     ]
    }
   ],
   "source": [
    "precision_sm = precision_score(y_test_sm, y_pred_sm)\n",
    "print('Precision del modelo Random Forest con Oversampling: %.3f' % precision_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo Random Forest con Oversampling: 0.935\n"
     ]
    }
   ],
   "source": [
    "recall_sm = recall_score(y_test_sm, y_pred_sm)\n",
    "print('Recall del Modelo Random Forest con Oversampling: %.3f' % recall_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[ 885 1067]\n",
      " [ 128 1845]]\n"
     ]
    }
   ],
   "source": [
    "matriz_sm = confusion_matrix(y_test_sm, y_pred_sm)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.45      0.60      1952\n",
      "        True       0.63      0.94      0.76      1973\n",
      "\n",
      "    accuracy                           0.70      3925\n",
      "   macro avg       0.75      0.69      0.68      3925\n",
      "weighted avg       0.75      0.70      0.68      3925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sm, y_pred_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest con Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_us, x_test_us, y_train_us, y_test_us = train_test_split(x_us, y_us,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_us = sc.fit_transform(x_train_us)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_us = sc.fit_transform(x_test_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_us = RandomForestClassifier(random_state = 50, n_estimators = 500)\n",
    "rf_us.fit(x_train_us, y_train_us)\n",
    "y_pred_us = rf_us.predict(x_test_us).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Random Forest con Undersampling: 0.589\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf_us = accuracy_score(y_test_us, y_pred_us)\n",
    "print('Accuracy del Random Forest con Undersampling: %.3f' % accuracy_rf_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo Random Forest con Undersampling 0.576\n"
     ]
    }
   ],
   "source": [
    "precision_us = precision_score(y_test_us, y_pred_us)\n",
    "print('Precision del modelo Random Forest con Undersampling %.3f' % precision_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo Random Forest con Undersampling: 0.560\n"
     ]
    }
   ],
   "source": [
    "recall_us = recall_score(y_test_us, y_pred_us)\n",
    "print('Recall del Modelo Random Forest con Undersampling: %.3f' % recall_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[236 147]\n",
      " [157 200]]\n"
     ]
    }
   ],
   "source": [
    "matriz_us = confusion_matrix(y_test_us, y_pred_us)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.62      0.61       383\n",
      "        True       0.58      0.56      0.57       357\n",
      "\n",
      "    accuracy                           0.59       740\n",
      "   macro avg       0.59      0.59      0.59       740\n",
      "weighted avg       0.59      0.59      0.59       740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_us, y_pred_us))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bg, x_test_bg, y_train_bg, y_test_bg = train_test_split(x, y,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_bg = sc.fit_transform(x_train_bg)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_bg = sc.fit_transform(x_test_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(n_jobs=-1, random_state=55)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging = BaggingClassifier(n_estimators = 10,\n",
    "                            random_state = 55, n_jobs = -1)\n",
    "\n",
    "bagging.fit(x_train_bg, y_train_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bg = bagging.predict(x_test_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Bagging: 0.814\n"
     ]
    }
   ],
   "source": [
    "accuracy_bg = accuracy_score(y_test_bg, y_pred_bg)\n",
    "print('Accuracy del Modelo de Bagging: %.3f' % accuracy_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Bagging: 0.235\n"
     ]
    }
   ],
   "source": [
    "precision_bg = precision_score(y_test_bg, y_pred_bg)\n",
    "print('Precision del Modelo de Bagging: %.3f' % precision_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Bagging: 0.040\n"
     ]
    }
   ],
   "source": [
    "recall_bg = recall_score(y_test_bg, y_pred_bg)\n",
    "print('Recall del Modelo de Bagging: %.3f' % recall_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[1883   52]\n",
      " [ 382   16]]\n"
     ]
    }
   ],
   "source": [
    "matriz_bg = confusion_matrix(y_test_bg, y_pred_bg)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.97      0.90      1935\n",
      "        True       0.24      0.04      0.07       398\n",
      "\n",
      "    accuracy                           0.81      2333\n",
      "   macro avg       0.53      0.51      0.48      2333\n",
      "weighted avg       0.73      0.81      0.76      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bg, y_pred_bg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_boo, x_test_boo, y_train_boo, y_test_boo = train_test_split(x, y,\n",
    "                                   random_state=42, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_boo = sc.fit_transform(x_train_boo)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_boo = sc.fit_transform(x_test_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='logloss', gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=3, max_leaves=0,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "boosting = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "boosting.fit(x_train_boo, y_train_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Boosting: 0.841\n"
     ]
    }
   ],
   "source": [
    "y_pred_boo = boosting.predict(x_test_boo)\n",
    "accuracy_boo = accuracy_score(y_test_boo, y_pred_boo)\n",
    "print('Accuracy del Modelo de Boosting: %.3f' % accuracy_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Boosting: 0.000\n"
     ]
    }
   ],
   "source": [
    "precision_boo = precision_score(y_test_boo, y_pred_boo)\n",
    "print('Precision del Modelo de Boosting: %.3f' % precision_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Boosting: 0.000\n"
     ]
    }
   ],
   "source": [
    "recall_boo = recall_score(y_test_boo, y_pred_boo)\n",
    "print('Recall del Modelo de Boosting: %.3f' % recall_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[1962    0]\n",
      " [ 371    0]]\n"
     ]
    }
   ],
   "source": [
    "matriz_boo = confusion_matrix(y_test_boo, y_pred_boo)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      1.00      0.91      1962\n",
      "        True       0.00      0.00      0.00       371\n",
      "\n",
      "    accuracy                           0.84      2333\n",
      "   macro avg       0.42      0.50      0.46      2333\n",
      "weighted avg       0.71      0.84      0.77      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_boo, y_pred_boo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_st, x_test_st, y_train_st, y_test_st = train_test_split(x, y,\n",
    "                                   random_state=42, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_st = sc.fit_transform(x_train_st)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_st = sc.fit_transform(x_test_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
       "                               ('gb',\n",
       "                                BaggingClassifier(n_estimators=100,\n",
       "                                                  random_state=42))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos_stacking = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', BaggingClassifier(n_estimators=100, random_state=42)),\n",
    "]\n",
    "\n",
    "meta_modelo = LogisticRegression()\n",
    "\n",
    "stacking = StackingClassifier(estimators=modelos_stacking, final_estimator=meta_modelo)\n",
    "\n",
    "stacking.fit(x_train_st, y_train_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Stacking: 0.840977\n"
     ]
    }
   ],
   "source": [
    "y_pred_st = stacking.predict(x_test_st)\n",
    "accuracy_st = accuracy_score(y_test_st, y_pred_st)\n",
    "print(f'Accuracy del Modelo de Stacking: {accuracy_st:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Stacking: 0.000\n"
     ]
    }
   ],
   "source": [
    "precision_st = precision_score(y_test_st, y_pred_st)\n",
    "print('Precision del Modelo de Stacking: %.3f' % precision_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Boosting: 0.000\n"
     ]
    }
   ],
   "source": [
    "recall_st = recall_score(y_test_st, y_pred_st)\n",
    "print('Recall del Modelo de Boosting: %.3f' % recall_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[1962    0]\n",
      " [ 371    0]]\n"
     ]
    }
   ],
   "source": [
    "matriz_st = confusion_matrix(y_test_st, y_pred_st)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      1.00      0.91      1962\n",
      "        True       0.00      0.00      0.00       371\n",
      "\n",
      "    accuracy                           0.84      2333\n",
      "   macro avg       0.42      0.50      0.46      2333\n",
      "weighted avg       0.71      0.84      0.77      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_st, y_pred_st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking con Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_smst, x_test_smst, y_train_smst, y_test_smst = train_test_split(x_sm, y_sm,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_smst = sc.fit_transform(x_train_smst)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_smst = sc.fit_transform(x_test_smst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
       "                               ('xg',\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None, gamma=None,\n",
       "                                              gpu_id=None, grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learning_rate=None, max_bin=None,\n",
       "                                              max_cat_to_onehot=None,\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None, max_leaves=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=42,\n",
       "                                              reg_alpha=None, reg_lambda=None, ...))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos_stacking = [\n",
    "   ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('xg', xgb.XGBClassifier(n_estimators=100, random_state=42)),\n",
    "]\n",
    "\n",
    "meta_modelo = LogisticRegression()\n",
    "\n",
    "stacking = StackingClassifier(estimators=modelos_stacking, final_estimator=meta_modelo)\n",
    "\n",
    "stacking.fit(x_train_smst, y_train_smst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Stacking con Oversampling: 0.545478\n"
     ]
    }
   ],
   "source": [
    "y_pred_smst = stacking.predict(x_test_smst)\n",
    "accuracy_smst = accuracy_score(y_test_smst, y_pred_smst)\n",
    "print(f'Accuracy del Modelo de Stacking con Oversampling: {accuracy_smst:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Stacking con Oversampling: 0.525\n"
     ]
    }
   ],
   "source": [
    "precision_smst = precision_score(y_test_smst, y_pred_smst)\n",
    "print('Precision del Modelo de Stacking con Oversampling: %.3f' % precision_smst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Stacking con Oversampling: 0.990\n"
     ]
    }
   ],
   "source": [
    "recall_smst = recall_score(y_test_smst, y_pred_smst)\n",
    "print('Recall del Modelo de Stacking con Oversampling: %.3f' % recall_smst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[ 188 1764]\n",
      " [  20 1953]]\n"
     ]
    }
   ],
   "source": [
    "matriz_smst = confusion_matrix(y_test_smst, y_pred_smst)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_smst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.10      0.17      1952\n",
      "        True       0.53      0.99      0.69      1973\n",
      "\n",
      "    accuracy                           0.55      3925\n",
      "   macro avg       0.71      0.54      0.43      3925\n",
      "weighted avg       0.71      0.55      0.43      3925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_smst, y_pred_smst))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
