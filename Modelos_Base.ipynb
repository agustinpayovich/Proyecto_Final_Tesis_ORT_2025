{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "\n",
    "    <td><img src=https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTZcU0_2fgIIcOXf6T0U0AQq1Ld4wMw9s1at5scGVpT5VEmPPTq6-CRSGJhQkrSSrSfi7o&usqp=CAU alt=\"Drawing\" style=\"width: 70px;\"/></td>\n",
    "\n",
    "    <td><td style=\"font-size:3vw\"><font color='OrangeRed'><b>Trabajo Final Master en Big Data</b></font></td>\n",
    "\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "\n",
    "    <td><img src=https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTZcU0_2fgIIcOXf6T0U0AQq1Ld4wMw9s1at5scGVpT5VEmPPTq6-CRSGJhQkrSSrSfi7o&usqp=CAU alt=\"Drawing\" style=\"width: 70px;\"/></td>\n",
    "\n",
    "    <td><td style=\"font-size:3vw\"><font color='OrangeRed'><b>Trabajo Final Master en Big Data</b></font></td>\n",
    "\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Final - Máster en Big Data - Fernández, García y Payovich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Base: Random Forest, Regresión Logística, Bagging, Boosting y Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split # División del dataset\n",
    "import matplotlib.pyplot as plt # Plotear\n",
    "from sklearn.linear_model import LinearRegression # Modelo de ML\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, classification_report # Métricas\n",
    "pd.options.display.max_columns= None\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación y Transformación de las Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base_final_EDA.csv', delimiter= ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['detractor'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['detractor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9812\n",
       "True     1850\n",
       "Name: detractor, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rf, x_test_rf, y_train_rf, y_test_rf = train_test_split(x, y,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_rf = sc.fit_transform(x_train_rf)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_rf = sc.fit_transform(x_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state = 50, n_estimators = 500)\n",
    "rf.fit(x_train_rf, y_train_rf)\n",
    "y_pred_rf = rf.predict(x_test_rf).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo Random Forest: 0.829\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf = accuracy_score(y_test_rf, y_pred_rf)\n",
    "print('Accuracy del modelo Random Forest: %.3f' % accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo Random Forest: 0.000\n"
     ]
    }
   ],
   "source": [
    "precision_rf = precision_score(y_test_rf, y_pred_rf)\n",
    "print('Precision del modelo Random Forest: %.3f' % precision_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo Random Forest: 0.000\n"
     ]
    }
   ],
   "source": [
    "recall_rf = recall_score(y_test_rf, y_pred_rf)\n",
    "print('Recall del Modelo Random Forest: %.3f' % recall_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[1935    0]\n",
      " [ 398    0]]\n"
     ]
    }
   ],
   "source": [
    "matriz_rf = confusion_matrix(y_test_rf, y_pred_rf)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      1.00      0.91      1935\n",
      "        True       0.00      0.00      0.00       398\n",
      "\n",
      "    accuracy                           0.83      2333\n",
      "   macro avg       0.41      0.50      0.45      2333\n",
      "weighted avg       0.69      0.83      0.75      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_rf, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest con Oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sm, x_test_sm, y_train_sm, y_test_sm = train_test_split(x, y,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OverSampling:\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 42)\n",
    "x_train_sm, y_train_sm = sm.fit_resample(x_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_sm = sc.fit_transform(x_train_sm)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_sm = sc.fit_transform(x_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_sm = RandomForestClassifier(random_state = 50, n_estimators = 500)\n",
    "rf_sm.fit(x_train_sm, y_train_sm)\n",
    "y_pred_sm = rf_sm.predict(x_test_sm).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Random Forest con Oversampling: 0.349\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf_sm = accuracy_score(y_test_sm, y_pred_sm)\n",
    "print('Accuracy del Random Forest con Oversampling: %.3f' % accuracy_rf_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo Random Forest con Oversampling: 0.182\n"
     ]
    }
   ],
   "source": [
    "precision_sm = precision_score(y_test_sm, y_pred_sm)\n",
    "print('Precision del modelo Random Forest con Oversampling: %.3f' % precision_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo Random Forest con Oversampling: 0.830\n"
     ]
    }
   ],
   "source": [
    "recall_sm = recall_score(y_test_sm, y_pred_sm)\n",
    "print('Recall del Modelo Random Forest con Oversampling: %.3f' % recall_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[ 492 1452]\n",
      " [  66  323]]\n"
     ]
    }
   ],
   "source": [
    "matriz_sm = confusion_matrix(y_test_sm, y_pred_sm)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.25      0.39      1944\n",
      "        True       0.18      0.83      0.30       389\n",
      "\n",
      "    accuracy                           0.35      2333\n",
      "   macro avg       0.53      0.54      0.35      2333\n",
      "weighted avg       0.77      0.35      0.38      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_sm, y_pred_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest con Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_us, x_test_us, y_train_us, y_test_us = train_test_split(x, y,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "x_train_us, y_train_us = rus.fit_resample(x_train_us, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_us = sc.fit_transform(x_train_us)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_us = sc.fit_transform(x_test_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_us = RandomForestClassifier(random_state = 50, n_estimators = 500)\n",
    "rf_us.fit(x_train_us, y_train_us)\n",
    "y_pred_us = rf_us.predict(x_test_us).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Random Forest con Undersampling: 0.615\n"
     ]
    }
   ],
   "source": [
    "accuracy_us = accuracy_score(y_test_us, y_pred_us)\n",
    "print('Accuracy del Random Forest con Undersampling: %.3f' % accuracy_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo Random Forest con Undersampling 0.222\n"
     ]
    }
   ],
   "source": [
    "precision_us = precision_score(y_test_us, y_pred_us)\n",
    "print('Precision del modelo Random Forest con Undersampling %.3f' % precision_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo Random Forest con Undersampling: 0.522\n"
     ]
    }
   ],
   "source": [
    "recall_us = recall_score(y_test_us, y_pred_us)\n",
    "print('Recall del Modelo Random Forest con Undersampling: %.3f' % recall_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[1232  712]\n",
      " [ 186  203]]\n"
     ]
    }
   ],
   "source": [
    "matriz_us = confusion_matrix(y_test_us, y_pred_us)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.63      0.73      1944\n",
      "        True       0.22      0.52      0.31       389\n",
      "\n",
      "    accuracy                           0.62      2333\n",
      "   macro avg       0.55      0.58      0.52      2333\n",
      "weighted avg       0.76      0.62      0.66      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_us, y_pred_us))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest con Balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rfb, x_test_rfb, y_train_rfb, y_test_rfb = train_test_split(x, y,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_rfb = sc.fit_transform(x_train_rfb)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_rfb = sc.fit_transform(x_test_rfb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfb = RandomForestClassifier(random_state = 50, n_estimators = 500, class_weight='balanced')\n",
    "rfb.fit(x_train_rfb, y_train_rfb)\n",
    "y_pred_rfb = rfb.predict(x_test_rfb).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Random Forest con Balanceo: 0.829\n"
     ]
    }
   ],
   "source": [
    "accuracy_rfb = accuracy_score(y_test_rfb, y_pred_rfb)\n",
    "print('Accuracy del Random Forest con Balanceo: %.3f' % accuracy_rfb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo Random Forest con Balanceo 0.000\n"
     ]
    }
   ],
   "source": [
    "precision_rfb = precision_score(y_test_rfb, y_pred_rfb)\n",
    "print('Precision del modelo Random Forest con Balanceo %.3f' % precision_rfb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo Random Forest con Balanceo: 0.000\n"
     ]
    }
   ],
   "source": [
    "recall_rfb = recall_score(y_test_rfb, y_pred_rfb)\n",
    "print('Recall del Modelo Random Forest con Balanceo: %.3f' % recall_rfb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rl, x_test_rl, y_train_rl, y_test_rl = train_test_split(x, y,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rlus, x_test_rlus, y_train_rlus, y_test_rlus = train_test_split(x, y,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rlsm, x_test_rlsm, y_train_rlsm, y_test_rlsm = train_test_split(x, y,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_rl = sc.fit_transform(x_train_rl)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_rl = sc.fit_transform(x_test_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "x_train_rlus, y_train_rlus = rus.fit_resample(x_train_rlus, y_train_rlus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OverSampling:\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 42)\n",
    "x_train_rlsm, y_train_rlsm = sm.fit_resample(x_train_rlsm, y_train_rlsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_rlus = sc.fit_transform(x_train_rlus)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_rlus = sc.fit_transform(x_test_rlus)\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_rlsm = sc.fit_transform(x_train_rlsm)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_rlsm = sc.fit_transform(x_test_rlsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "rl = LogisticRegression(max_iter=1000)\n",
    "rl.fit(x_train_rl, y_train_rl)\n",
    "y_pred_rl = rl.predict(x_test_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "rlus = LogisticRegression(max_iter=1000)\n",
    "rlus.fit(x_train_rlus, y_train_rlus)\n",
    "y_pred_rlus = rlus.predict(x_test_rlus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlsm = LogisticRegression(max_iter=1000)\n",
    "rlsm.fit(x_train_rlsm, y_train_rlsm)\n",
    "y_pred_rlsm = rlsm.predict(x_test_rlsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Regresión Logística: 0.829\n"
     ]
    }
   ],
   "source": [
    "accuracy_rl = accuracy_score(y_test_rl, y_pred_rl)\n",
    "print('Accuracy del Modelo de Regresión Logística: %.3f' % accuracy_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Regresión Logística con Undersampling: 0.512\n"
     ]
    }
   ],
   "source": [
    "accuracy_rlus = accuracy_score(y_test_rlus, y_pred_rlus)\n",
    "print('Accuracy del Modelo de Regresión Logística con Undersampling: %.3f' % accuracy_rlus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Regresión Logística con Oversampling: 0.185\n"
     ]
    }
   ],
   "source": [
    "accuracy_rlsm = accuracy_score(y_test_rlsm, y_pred_rlsm)\n",
    "print('Accuracy del Modelo de Regresión Logística con Oversampling: %.3f' % accuracy_rlsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Regresión Logística 0.000\n"
     ]
    }
   ],
   "source": [
    "precision_rl = precision_score(y_test_rl, y_pred_rl)\n",
    "print('Precision del Modelo de Regresión Logística %.3f' % precision_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Regresión Logística con Undersampling 0.205\n"
     ]
    }
   ],
   "source": [
    "precision_rlus = precision_score(y_test_rlus, y_pred_rlus)\n",
    "print('Precision del Modelo de Regresión Logística con Undersampling %.3f' % precision_rlus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Regresión Logística con Oversampling 0.173\n"
     ]
    }
   ],
   "source": [
    "precision_rlsm = precision_score(y_test_rlsm, y_pred_rlsm)\n",
    "print('Precision del Modelo de Regresión Logística con Oversampling %.3f' % precision_rlsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Regresión Logística: 0.000\n"
     ]
    }
   ],
   "source": [
    "recall_rl = recall_score(y_test_rl, y_pred_rl)\n",
    "print('Recall del Modelo de Regresión Logística: %.3f' % recall_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Regresión Logística con Undersampling: 0.648\n"
     ]
    }
   ],
   "source": [
    "recall_rlus = recall_score(y_test_rlus, y_pred_rlus)\n",
    "print('Recall del Modelo de Regresión Logística con Undersampling: %.3f' % recall_rlus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Regresión Logística con Oversampling: 0.995\n"
     ]
    }
   ],
   "source": [
    "recall_rlsm = recall_score(y_test_rlsm, y_pred_rlsm)\n",
    "print('Recall del Modelo de Regresión Logística con Oversampling: %.3f' % recall_rlsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bg, x_test_bg, y_train_bg, y_test_bg = train_test_split(x, y,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bgus, x_test_bgus, y_train_bgus, y_test_bgus = train_test_split(x, y,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bgsm, x_test_bgsm, y_train_bgsm, y_test_bgsm = train_test_split(x, y,\n",
    "                                   random_state=130, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_bg = sc.fit_transform(x_train_bg)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_bg = sc.fit_transform(x_test_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_bgus = sc.fit_transform(x_train_bgus)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_bgus = sc.fit_transform(x_test_bgus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_bgsm = sc.fit_transform(x_train_bgsm)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_bgsm = sc.fit_transform(x_test_bgsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "x_train_bgus, y_train_bgus = rus.fit_resample(x_train_bgus, y_train_bgus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OverSampling:\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 42)\n",
    "x_train_bgsm, y_train_bgsm = sm.fit_resample(x_train_bgsm, y_train_bgsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging = BaggingClassifier(n_estimators = 10,\n",
    "                            random_state = 55, n_jobs = -1)\n",
    "\n",
    "bagging.fit(x_train_bg, y_train_bg)\n",
    "y_pred_bg = bagging.predict(x_test_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "baggingus = BaggingClassifier(n_estimators = 10,\n",
    "                            random_state = 55, n_jobs = -1)\n",
    "\n",
    "baggingus.fit(x_train_bgus, y_train_bgus)\n",
    "y_pred_bgus = baggingus.predict(x_test_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "baggingsm = BaggingClassifier(n_estimators = 10,\n",
    "                            random_state = 55, n_jobs = -1)\n",
    "\n",
    "baggingsm.fit(x_train_bgsm, y_train_bgsm)\n",
    "y_pred_bgsm = baggingsm.predict(x_test_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Bagging: 0.814\n"
     ]
    }
   ],
   "source": [
    "accuracy_bg = accuracy_score(y_test_bg, y_pred_bg)\n",
    "print('Accuracy del Modelo de Bagging: %.3f' % accuracy_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Bagging con Undersampling: 0.659\n"
     ]
    }
   ],
   "source": [
    "accuracy_bgus = accuracy_score(y_test_bgus, y_pred_bgus)\n",
    "print('Accuracy del Modelo de Bagging con Undersampling: %.3f' % accuracy_bgus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Bagging con Oversampling: 0.212\n"
     ]
    }
   ],
   "source": [
    "accuracy_bgsm = accuracy_score(y_test_bgsm, y_pred_bgsm)\n",
    "print('Accuracy del Modelo de Bagging con Oversampling: %.3f' % accuracy_bgsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Bagging: 0.235\n"
     ]
    }
   ],
   "source": [
    "precision_bg = precision_score(y_test_bg, y_pred_bg)\n",
    "print('Precision del Modelo de Bagging: %.3f' % precision_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Bagging con Undersampling: 0.202\n"
     ]
    }
   ],
   "source": [
    "precision_bgus = precision_score(y_test_bgus, y_pred_bgus)\n",
    "print('Precision del Modelo de Bagging con Undersampling: %.3f' % precision_bgus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Bagging con Oversampling: 0.171\n"
     ]
    }
   ],
   "source": [
    "precision_bgsm = precision_score(y_test_bgsm, y_pred_bgsm)\n",
    "print('Precision del Modelo de Bagging con Oversampling: %.3f' % precision_bgsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Bagging: 0.040\n"
     ]
    }
   ],
   "source": [
    "recall_bg = recall_score(y_test_bg, y_pred_bg)\n",
    "print('Recall del Modelo de Bagging: %.3f' % recall_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Bagging con Undersampling: 0.337\n"
     ]
    }
   ],
   "source": [
    "recall_bgus = recall_score(y_test_bgus, y_pred_bgus)\n",
    "print('Recall del Modelo de Bagging con Undersampling: %.3f' % recall_bgus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Bagging con Oversampling: 0.940\n"
     ]
    }
   ],
   "source": [
    "recall_bgsm = recall_score(y_test_bgsm, y_pred_bgsm)\n",
    "print('Recall del Modelo de Bagging con Oversampling: %.3f' % recall_bgsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión Bagging:\n",
      "[[1883   52]\n",
      " [ 382   16]]\n"
     ]
    }
   ],
   "source": [
    "matriz_bg = confusion_matrix(y_test_bg, y_pred_bg)\n",
    "print('Matriz de Confusión Bagging:')\n",
    "print(matriz_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.97      0.90      1935\n",
      "        True       0.24      0.04      0.07       398\n",
      "\n",
      "    accuracy                           0.81      2333\n",
      "   macro avg       0.53      0.51      0.48      2333\n",
      "weighted avg       0.73      0.81      0.76      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_bg, y_pred_bg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_boo, x_test_boo, y_train_boo, y_test_boo = train_test_split(x, y,\n",
    "                                   random_state=42, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_boo1, x_test_boo1, y_train_boo1, y_test_boo1 = train_test_split(x, y,\n",
    "                                   random_state=42, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='logloss', gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=3, max_leaves=0,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "boosting.fit(x_train_boo, y_train_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='logloss', gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=3, max_leaves=0,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting1 = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=9\n",
    ")\n",
    "\n",
    "boosting1.fit(x_train_boo1, y_train_boo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Boosting: 0.841\n"
     ]
    }
   ],
   "source": [
    "y_pred_boo = boosting.predict(x_test_boo)\n",
    "accuracy_boo = accuracy_score(y_test_boo, y_pred_boo)\n",
    "print('Accuracy del Modelo de Boosting: %.3f' % accuracy_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Boosting Sampleado: 0.365\n"
     ]
    }
   ],
   "source": [
    "y_pred_boo1 = boosting1.predict(x_test_boo1)\n",
    "accuracy_boo1 = accuracy_score(y_test_boo1, y_pred_boo1)\n",
    "print('Accuracy del Modelo de Boosting Sampleado: %.3f' % accuracy_boo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Boosting: 0.500\n"
     ]
    }
   ],
   "source": [
    "precision_boo = precision_score(y_test_boo, y_pred_boo)\n",
    "print('Precision del Modelo de Boosting: %.3f' % precision_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Boosting Sampleado: 0.185\n"
     ]
    }
   ],
   "source": [
    "precision_boo1 = precision_score(y_test_boo1, y_pred_boo1)\n",
    "print('Precision del Modelo de Boosting Sampleado: %.3f' % precision_boo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Boosting: 0.003\n"
     ]
    }
   ],
   "source": [
    "recall_boo = recall_score(y_test_boo, y_pred_boo)\n",
    "print('Recall del Modelo de Boosting: %.3f' % recall_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Boosting Samp: 0.876\n"
     ]
    }
   ],
   "source": [
    "recall_boo1 = recall_score(y_test_boo1, y_pred_boo1)\n",
    "print('Recall del Modelo de Boosting Samp: %.3f' % recall_boo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de Boosting:\n",
      "[[1961    1]\n",
      " [ 370    1]]\n"
     ]
    }
   ],
   "source": [
    "matriz_boo = confusion_matrix(y_test_boo, y_pred_boo)\n",
    "print('Matriz de Confusión de Boosting:')\n",
    "print(matriz_boo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      1.00      0.91      1962\n",
      "        True       0.50      0.00      0.01       371\n",
      "\n",
      "    accuracy                           0.84      2333\n",
      "   macro avg       0.67      0.50      0.46      2333\n",
      "weighted avg       0.79      0.84      0.77      2333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_boo, y_pred_boo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_st, x_test_st, y_train_st, y_test_st = train_test_split(x, y,\n",
    "                                   random_state=42, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_stsm, x_test_stsm, y_train_stsm, y_test_stsm = train_test_split(x, y,\n",
    "                                   random_state=42, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_stus, x_test_stus, y_train_stus, y_test_stus = train_test_split(x, y,\n",
    "                                   random_state=42, \n",
    "                                   test_size=0.20, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_st = sc.fit_transform(x_train_st)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_st = sc.fit_transform(x_test_st)\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_stsm = sc.fit_transform(x_train_stsm)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_stsm = sc.fit_transform(x_test_stsm)\n",
    "#Escalo Datos de Entrenamiento:\n",
    "x_train_stus = sc.fit_transform(x_train_stus)\n",
    "#Escalo Datos de Testeo:\n",
    "x_test_stus = sc.fit_transform(x_test_stus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
       "                               ('gb',\n",
       "                                BaggingClassifier(n_estimators=100,\n",
       "                                                  random_state=42))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos_stacking = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', BaggingClassifier(n_estimators=100, random_state=42)),\n",
    "]\n",
    "\n",
    "meta_modelo = LogisticRegression()\n",
    "\n",
    "stacking = StackingClassifier(estimators=modelos_stacking, final_estimator=meta_modelo)\n",
    "\n",
    "stacking.fit(x_train_st, y_train_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
       "                               ('gb',\n",
       "                                BaggingClassifier(n_estimators=100,\n",
       "                                                  random_state=42))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos_stackingsm = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', BaggingClassifier(n_estimators=100, random_state=42)),\n",
    "]\n",
    "\n",
    "meta_modelo = LogisticRegression()\n",
    "\n",
    "stackingsm = StackingClassifier(estimators=modelos_stacking, final_estimator=meta_modelo)\n",
    "\n",
    "stackingsm.fit(x_train_stsm, y_train_stsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
       "                               ('gb',\n",
       "                                BaggingClassifier(n_estimators=100,\n",
       "                                                  random_state=42))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos_stackingus = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('gb', BaggingClassifier(n_estimators=100, random_state=42)),\n",
    "]\n",
    "\n",
    "meta_modelo = LogisticRegression()\n",
    "\n",
    "stackingus = StackingClassifier(estimators=modelos_stacking, final_estimator=meta_modelo)\n",
    "\n",
    "stackingus.fit(x_train_stus, y_train_stus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Stacking: 0.840977\n"
     ]
    }
   ],
   "source": [
    "y_pred_st = stacking.predict(x_test_st)\n",
    "accuracy_st = accuracy_score(y_test_st, y_pred_st)\n",
    "print(f'Accuracy del Modelo de Stacking: {accuracy_st:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Stacking con Oversampling: 0.840977\n"
     ]
    }
   ],
   "source": [
    "y_pred_stsm = stacking.predict(x_test_stsm)\n",
    "accuracy_stsm = accuracy_score(y_test_stsm, y_pred_stsm)\n",
    "print(f'Accuracy del Modelo de Stacking con Oversampling: {accuracy_stsm:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del Modelo de Stacking con Oversampling: 0.840977\n"
     ]
    }
   ],
   "source": [
    "y_pred_stus = stacking.predict(x_test_stus)\n",
    "accuracy_stus = accuracy_score(y_test_stus, y_pred_stus)\n",
    "print(f'Accuracy del Modelo de Stacking con Oversampling: {accuracy_stus:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Stacking: 0.000\n"
     ]
    }
   ],
   "source": [
    "precision_st = precision_score(y_test_st, y_pred_st)\n",
    "print('Precision del Modelo de Stacking: %.3f' % precision_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Stacking con Oversampling: 0.000\n"
     ]
    }
   ],
   "source": [
    "precision_stsm = precision_score(y_test_stsm, y_pred_stsm)\n",
    "print('Precision del Modelo de Stacking con Oversampling: %.3f' % precision_stsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del Modelo de Stacking con Undersampling: 0.000\n"
     ]
    }
   ],
   "source": [
    "precision_stus = precision_score(y_test_stus, y_pred_stus)\n",
    "print('Precision del Modelo de Stacking con Undersampling: %.3f' % precision_stus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Stacking: 0.000\n"
     ]
    }
   ],
   "source": [
    "recall_st = recall_score(y_test_st, y_pred_st)\n",
    "print('Recall del Modelo de Stacking: %.3f' % recall_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Stacking con Undersampling: 0.000\n"
     ]
    }
   ],
   "source": [
    "recall_stsm = recall_score(y_test_stsm, y_pred_stsm)\n",
    "print('Recall del Modelo de Stacking con Undersampling: %.3f' % recall_stsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall del Modelo de Stacking con Undersampling: 0.000\n"
     ]
    }
   ],
   "source": [
    "recall_stus = recall_score(y_test_stus, y_pred_stus)\n",
    "print('Recall del Modelo de Stacking con Undersampling: %.3f' % recall_stus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión de Boosting:\n",
      "[[1962    0]\n",
      " [ 371    0]]\n"
     ]
    }
   ],
   "source": [
    "matriz_st = confusion_matrix(y_test_st, y_pred_st)\n",
    "print('Matriz de Confusión de Boosting:')\n",
    "print(matriz_st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
